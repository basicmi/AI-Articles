# AI Articles of the week

**[ARM STANDS ON SHOULDERS OF GIANTS WITH FIRST GENERATION AI PROCESSOR](https://www.nextplatform.com/2018/08/22/arm-stands-on-shoulders-of-giants-with-first-generation-ai-processor/)**
> This week at the annual Hot Chips conference Arm presented its first generation machine learning processor, the IP of which should be available to partners later this year.

**[A MYTHIC APPROACH TO DEEP LEARNING INFERENCE](https://www.nextplatform.com/2018/08/23/a-mythic-approach-to-deep-learning-inference/)**
> Mythic, which was founded in 2012 by Dave Fick (also CTO) and a colleague from the Michigan Integrated Circuits lab has managed to raise $55 million from a number of investors, including SoftBank for its ultra low-power approach to inference at the edge. What is unique here is not just the hardware approach but also that the inference chip puts server class silicon to the test in terms of capability and certainly power consumption.

**[Give AI curiosity, and it will watch TV forever](https://qz.com/1366484/give-ai-curiosity-and-it-will-watch-tv-forever/)**
> some AI researchers are exploring how to give algorithms a sense of curiosity, so they can learn without any human guidance. ...But curiosity comes with a cost. 

**[The International 2018: Results](https://blog.openai.com/the-international-2018-results/)**
> OpenAI Five lost two games against top Dota 2 players at The International in Vancouver this week, maintaining a good chance of winning for the first 20-35 minutes of both games. 

**[Music and Machine Learning](http://ai.sensilab.monash.edu/2018/08/23/Neural-Music/)**
> Algorithmic music composition has always had a place in computing. One of the first applications Ada Lovelace proposed for the Analytic Engine almost 200 years ago was the generation of music compositions. 200 years has seen a lot of progress in this area but has also reiterated something musicians have always known… writing music is hard.

**[The Lever](https://medium.com/the-lever)**
> Applied Machine Learning best practices

**[Exploring Adversarial Reprogramming](https://rajatvd.github.io/Exploring-Adversarial-Reprogramming/)**
> Google brain recently published a paper titled [Adversarial Reprogramming of Neural Networks](https://arxiv.org/pdf/1806.11146.pdf) which caught my attention. It introduced a new kind of adversarial example for neural networks, those which could actually perform a useful task for the adversary as opposed to just fooling the attacked network. ...I’m going to walk through the paper in this post, and also add some of my own small modifications to the work they presented in the paper. 

**[Uncertainty for CTR Prediction: One Model to Clarify Them All](https://engineering.taboola.com/uncertainty-ctr-prediction-one-model-clarify/)**
> In the [first post](https://engineering.taboola.com/using-uncertainty-interpret-model/) of the series we discussed three types of uncertainty that can affect your model – data uncertainty, model uncertainty and measurement uncertainty. In [the second post](https://engineering.taboola.com/neural-networks-bayesian-perspective/) we talked about various methods to handle the model uncertainty specifically . Then, in our [third post](https://engineering.taboola.com/recommender-systems-exploring-the-unknown-using-uncertainty/) we showed how we can use the model’s uncertainty to encourage exploration of new items in recommender systems.

**[vid2vid](https://github.com/NVIDIA/vid2vid)**
> Pytorch implementation for high-resolution (e.g., 2048x1024) photorealistic video-to-video translation. It can be used for turning semantic label maps into photo-realistic videos, synthesizing people talking from edge maps, or generating human motions from poses. 
