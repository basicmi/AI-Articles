## Weekly Digest 2018-02 \#1



**[INSIDE AMAZON'S ARTIFICIAL INTELLIGENCE FLYWHEEL](https://www.wired.com/story/amazon-artificial-intelligence-flywheel)**
> Alexa, how is Amazon doing in AI?

**[THE WIRED GUIDE TO ARTIFICIAL INTELLIGENCE](https://www.wired.com/story/guide-artificial-intelligence/)**
> Supersmart algorithms won't take all the jobs, but they are learning faster than ever, doing everything from medical diagnostics to serving up ads.

**[GREEDY, BRITTLE, OPAQUE, AND SHALLOW: THE DOWNSIDES TO DEEP LEARNING](https://www.wired.com/story/greedy-brittle-opaque-and-shallow-the-downsides-to-deep-learning/)**
> We've been promised a revolution in how and why nearly everything happens. But the limits of modern artificial intelligence are closer than we think.

**[Are Autonomous Cars Really Safer than Human Drivers?](https://www.scientificamerican.com/article/are-autonomous-cars-really-safer-than-human-drivers/)**
> Most comparisons between human drivers and automated vehicles have been at best uneven, and at worst, unfair

**[MIT is aiming for AI moonshots with Intelligence Quest](https://techcrunch.com/2018/02/01/mit-is-aiming-for-ai-moonshots-with-intelligence-quest/)**
> This week, the school announced the launch of the [MIT Intelligence Quest](http://news.mit.edu/2018/mit-launches-intelligence-quest-0201), an initiative aimed at leveraging its AI research into something it believes could be game-changing for the category. The school has divided its plan into two distinct categories: “The Core” and “The Bridge.”

**[More efficient machine learning could upend the AI paradigm](https://www.technologyreview.com/s/610095/more-efficient-machine-learning-could-upend-the-ai-paradigm/)**
> Smaller algorithms that don’t need mountains of data to train are coming.

**[Is There a Trade-off Between Immediate and Longer-term AI Safety Efforts?](https://futureoflife.org/2018/01/29/trade-off-immediate-longer-term-ai-safety-efforts/)**
> Something I often hear in the machine learning community and media articles is “Worries about superintelligence are a distraction from the *real* problem X that we are facing today with AI” (where X = algorithmic bias, technological unemployment, interpretability, data privacy, etc). This competitive attitude gives the impression that immediate and longer-term safety concerns are in conflict. But is there actually a tradeoff between them?

**[Amazon Wants to Disrupt Health Care in America. In China, Tech Giants Already Have.](https://www.nytimes.com/2018/01/31/technology/amazon-china-health-care-ai.html)**
> Amazon and two other American titans are trying to shake up health care by experimenting with their own employees’ coverage. By Chinese standards, they’re behind the curve.
> Technology companies like Alibaba and Tencent have made health care a priority for years, and are using China as their laboratory. After testing online medical advice and drug tracking systems, they are now focused on a more advanced tool: artificial intelligence.

**[The Shallowness of Google Translate](https://www.theatlantic.com/technology/archive/2018/01/the-shallowness-of-google-translate/551570/)**
> The program uses state-of-the-art AI techniques, but simple tests show that it's a long way from real understanding.

**[SELF-DRIVING CARS HAVE A SECRET WEAPON: REMOTE CONTROL](https://www.wired.com/story/phantom-teleops)**

**[Optimization over Explanation](https://medium.com/berkman-klein-center/optimization-over-explanation-41ecb135763d)**
> DON’T MAKE AI ARTIFICIALLY STUPID IN THE NAME OF TRANSPARENCY

**[Lessons from Optics, The Other Deep Learning](http://www.argmin.net/2018/01/25/optics/)**
> A small group of colleagues and I have started a massive empirical effort to catalogue mental models that are ambient in our field, to formalize them, and to then validate them with experiments. It’s a lot of work. I think it’s the first step to developing a layered mental model of deep learning that you could teach in high schools.

**[Autonomous Driving using End-to-End Deep Learning: an AirSim tutorial](https://github.com/Microsoft/AutonomousDrivingCookbook/tree/master/AirSimE2EDeepLearning)**
> In this tutorial, you will learn how to train and test an end-to-end deep learning model for autonomous driving using data collected from the [AirSim simulation environment](https://github.com/Microsoft/AirSim). You will train a model to learn how to steer a car through a portion of the Mountain/Landscape map in AirSim using a single front facing webcam for visual input. Such a task is usually considered the "hello world" of autonomous driving, but after finishing this tutorial you will have enough background to start exploring new ideas on your own. Through the length of this tutorial, you will also learn some practical aspects and nuances of working with end-to-end deep learning methods.

**[The Matrix Calculus You Need For Deep Learning](http://parrt.cs.usfca.edu/doc/matrix-calculus/index.html)**
> This paper is an attempt to explain all the matrix calculus you need in order to understand the training of deep neural networks. 

