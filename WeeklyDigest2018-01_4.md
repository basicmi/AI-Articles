## Weekly Digest 2018-01 \#3

**[The Google Brain Team — Looking Back on 2017 (Part 1 of 2)](https://research.googleblog.com/2018/01/the-google-brain-team-looking-back-on.html)**
**[The Google Brain Team — Looking Back on 2017 (Part 2 of 2)](https://research.googleblog.com/2018/01/the-google-brain-team-looking-back-on_12.html)**
> The [Google Brain team](https://g.co/brain) works to advance the state of the art in artificial intelligence by research and systems engineering, as one part of the overall [Google AI](https://ai.google/) effort. Last year we [shared](https://research.googleblog.com/2017/01/the-google-brain-team-looking-back-on.html) a summary of our work in 2016. Since then, we’ve continued to make progress on our long-term research agenda of making machines intelligent, and have collaborated with a number of teams across [Google](https://research.google.com/) and [Alphabet](https://abc.xyz/) to use the results of our research to improve people’s lives. This first of two posts will highlight some of our work in 2017, including some of our basic research work, as well as updates on open source software, datasets, and new hardware for [machine learning](https://en.wikipedia.org/wiki/Machine_learning). In the second post we’ll dive into the research we do in specific domains where machine learning can have a large impact, such as healthcare, robotics, and some areas of basic science, as well as cover our work on creativity, fairness and inclusion and tell you a bit more about who we are.

**[Cloud AutoML: Making AI accessible to every business](https://www.blog.google/topics/google-cloud/cloud-automl-making-ai-accessible-every-business/)**
> [Cloud AutoML](https://cloud.google.com/automl/) helps businesses with limited ML expertise start building their own high-quality custom models by using advanced techniques like [learning2learn](https://www.safaribooksonline.com/library/view/oreilly-artificial-intelligence/9781491985250/video314918.html) and [transfer learning](https://en.wikipedia.org/wiki/Transfer_learning) from Google. We believe Cloud AutoML will make AI experts even more productive, advance new fields in AI and help less-skilled engineers build powerful AI systems they previously only dreamed of.

**[Alexa, What Are You Doing with My Family's Personal Info?](https://www.scientificamerican.com/article/alexa-what-are-you-doing-with-my-familys-personal-info/)**
> Amazon Alexa, Google Assistant and several smart-home technologies that debuted at last week’s CES add convenience but also raise privacy concerns

**[No, machines can’t read better than humans](https://www.theverge.com/2018/1/17/16900292/ai-reading-comprehension-machines-humans)**
> Headlines have claimed AIs outperform humans at ‘reading comprehension,’ but in reality they’ve got a long way to go

**[How to Design Social Systems (Without Causing Depression and War)](https://medium.com/what-to-build/how-to-design-social-systems-without-causing-depression-and-war-3c3f8e0226d1)**
> "In my [note to Mark Zuckerberg](https://medium.com/what-to-build/dear-zuck-fd25ecb1aa5a) (which you probably want to read first), I urged his team and other technologists to reimagine their products as “practice spaces” — virtual places where people practice the kinds of acts and relationships they find meaningful."

**[Getting Started with TensorFlow: A Machine Learning Tutorial](https://www.toptal.com/machine-learning/tensorflow-machine-learning-tutorial)**
> TensorFlow is an open source software library created by Google that is used to implement machine learning and deep learning systems. These two names contain a series of powerful algorithms that share a common challenge—to allow a computer to learn how to automatically spot complex patterns and/or to make best possible decisions.
> If you’re interested in details about these systems, you can learn more from the Toptal blog posts on [machine learning](https://www.toptal.com/machine-learning/machine-learning-theory-an-introductory-primer) and [deep learning](https://www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks).

**[In defense of skepticism about deep learning](https://medium.com/@GaryMarcus/in-defense-of-skepticism-about-deep-learning-6e8bfd5ae0f1)**
> "In a recent appraisal of deep learning (Marcus, 2018) I outlined ten challenges for deep learning, and suggested that deep learning by itself, although useful, was unlikely to lead on its own to artificial general intelligence. I suggested instead the deep learning be viewed “not as a universal solvent, but simply as one tool among many.”"

**[Introduction to Various Reinforcement Learning Algorithms. Part I (Q-Learning, SARSA, DQN, DDPG)](https://towardsdatascience.com/introduction-to-various-reinforcement-learning-algorithms-i-q-learning-sarsa-dqn-ddpg-72a5e0cb6287)**
> Reinforcement Learning (RL) refers to a kind of Machine Learning method in which the agent receives a delayed reward in the next time step to evaluate its previous action. It was mostly used in games (e.g. Atari, Mario), with performance on par with or even exceeding humans. Recently, as the algorithm evolves with the combination of Neural Networks, it is capable of solving more complex tasks, such as the pendulum problem:

**[I trained fake news detection AI with >95% accuracy, and almost went crazy](https://towardsdatascience.com/i-trained-fake-news-detection-ai-with-95-accuracy-and-almost-went-crazy-d10589aa57c)**
>  We made a fake news detector with above a 95% accuracy (on a validation set) that uses machine learning and Natural Language Processing that you can download [here](https://goo.gl/2cvBmp). In the real world, the accuracy might be lower, especially as time goes on and the way articles are written changes.

**[The light and dark of AI-powered smartphones](https://techcrunch.com/2018/01/06/the-light-and-dark-of-ai-powered-smartphones)**
> Analyst Gartner put out a [10-strong listicle](https://www.gartner.com/document/3840591) this week identifying what it dubbed “high-impact” uses for AI-powered features on smartphones that it suggests will enable device vendors to provide “more value” to customers via the medium of “more advanced” user experiences.

**[What AI can and can’t do (yet) for your business](https://www.mckinsey.com/business-functions/mckinsey-analytics/our-insights/what-ai-can-and-cant-do-yet-for-your-business)**
> Artificial intelligence is a moving target. Here’s how to take better aim.

**[Best of CES 2018: The one company vital to gaming, self-driving cars, and AI](https://qz.com/1179116/best-of-ces-2018-nvidias-chips-googles-thirst-razers-project-linda-riding-modobag)**
> Quartz’s time at the Consumer Electronics Show in Las Vegas has come to a close, and we’ve reflected on a week of being inundated with gadgets, technology, and pitches.

**[Optimizing Mobile Deep Learning on ARM GPU with TVM](http://tvmlang.org/2018/01/16/opt-mali-gpu.html)**
> TVM addresses the difficulty of deploying for different hardwares by introducing an unified IR stack, with which the optimization for different hardwares can be done easily. In this post, we show how we use [TVM](http://tvmlang.org/2017/08/17/tvm-release-announcement.html)/[NNVM](http://tvmlang.org/2017/10/06/nnvm-compiler-announcement.html) to generate efficient kernels for ARM Mali GPU and do end-to-end compilation. In our test on Mali-T860 MP4, compared with [Arm Compute Library](https://developer.arm.com/technologies/compute-library), our method is 1.4x faster on VGG-16 and 2.2x faster on MobileNet. Both graph-level and operator-level optimization contribute to this speed up.

**[My Journey Into Data Science and Bio-Informatics — Part 1: Programming](https://towardsdatascience.com/my-journey-into-data-science-and-bio-informatics-749ece4d8860)**
> “Algorithms are the new drugs, and doctors the new technology prescribers.” — Hugh Harvey, radiologist
