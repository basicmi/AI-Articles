# Interesting stuff of AI/ML/DL

## Weekly Digest 2017-11 \#2

**[Capsule Networks Are Shaking up AI — Here’s How to Use Them](https://hackernoon.com/capsule-networks-are-shaking-up-ai-heres-how-to-use-them-c233a0971952)**
> If you follow AI you might have heard about the advent of the potentially revolutionary Capsule Networks. I will show you how you can start using them today.

**[Capsule Networks Explained](https://kndrck.co/posts/capsule_networks_explained/)**
> Using a novel architecture that mimics the human vision system, Capsule Networks strives for translation equivariance instead of translation invariance, allowing it to generalize to a greater degree from different view points with less training data.
> You can check out a [barebone implementation](https://gist.github.com/kendricktan/9a776ec6322abaaf03cc9befd35508d4) of Capsule Network here, which is just a cleaned up version of [gram.ai’s implementaion](https://github.com/gram-ai/capsule-networks).

**[AI vs Doctors](https://www.strategy-business.com/article/Are-We-on-the-Verge-of-a-New-Golden-Age)**
> Artificial intelligence is challenging doctors on their home turf. We’re keeping score.

**[Software 2.0](https://medium.com/@karpathy/software-2-0-a64152b37c35)**
> I sometimes see people refer to neural networks as just “another tool in your machine learning toolbox”. They have some pros and cons, they work here or there, and sometimes you can use them to win Kaggle competitions. Unfortunately, this interpretation completely misses the forest for the trees. Neural networks are not just another classifier, they represent the beginning of a fundamental shift in how we write software. They are Software 2.0.

**[Is Deep Learning “Software 2.0”?](https://medium.com/intuitionmachine/is-deep-learning-software-2-0-cc7ad46b138f)**
> Andrej Karpathy wrote an article about what he calls “Software 2.0”. Karpathy (Director of AI at Tesla) makes the argument that Neural Networks (or Deep Learning) is a new kind of software. I do agree that there indeed exists a trend towards “teachable machines” as opposed to the more conventional programmable machines, however I do have an issue with some of the benefits that Karpathy mentions to back-up his thesis.

**[This AI Bot That Messes With Email Scammers As Long As Possible Is Brilliant](http://digg.com/2017/re-scam-ai-scammer)**
> Email scammers work in bulk, blasting out tons of emails in the hopes of getting a few bites which they can follow up on. To counter this, NetSafe, an online safety non-profit in New Zealand, built Re:scam, which messes with scammers automatically.

**[PART II: Routes to defensibility for your AI Startup](https://machinelearnings.co/part-ii-routes-to-defensibility-for-your-ai-startups-acdb141e38ce)**
> A few weeks ago I published a post in which I outline a framework to think about ways to create moats for AI startups. It triggered interesting conversations with several AI practitioners (founders, product managers, VCs) over the past few days. I think these debates bring interesting complements to my initial framework, so I eventually decided to publish 3 of them here.

**[The Next Phase Of Machine Learning](https://semiengineering.com/the-next-phase-of-machine-learning/)**
> Chipmakers turn to inferencing as the next big opportunity for this technology.

**[AlphaGo Zero Explained In One Diagram](https://medium.com/applied-data-science/alphago-zero-explained-in-one-diagram-365f5abf67e0)**
> Get the full cheat sheet [here](https://applied-data.science/blog/alphago-zero-cheat-sheet)

**[The Neural Networks API is available in Android 8.1 and higher system images](https://developer.android.com/ndk/guides/neuralnetworks/index.html)**
> The Android Neural Networks API (NNAPI) is an Android C API designed for running computationally intensive operations for machine learning on mobile devices. NNAPI is designed to provide a base layer of functionality for higher-level machine learning frameworks (such as TensorFlow Lite, Caffe2, or others) that build and train neural networks. The API is available on all devices running Android 8.1 (API level 27) or higher.

**[AI Chip Explosion: Cambricon’s Billion-Device Ambition](https://syncedreview.com/2017/11/06/ai-chip-explosion-cambricons-billion-device-ambition/)**
> On November 6 in Beijing, China’s rising semiconductor company Cambricon released the Cambrian-1H8 for low power consumption computer vision application, the higher-end Cambrian-1H16 for more general purpose application, the Cambrian-1M for autonomous driving applications with yet-to-be-disclosed release date, and an AI system software named Cambrian NeuWare.

**[A List of Chip/IP for Deep Learning (keep updating)](https://basicmi.github.io/Deep-Learning-Processor-List/)**
> Machine Learning, especially Deep Learning technology is driving the evolution of artificial intelligence (AI). At the beginning, deep learning has primarily been a software play. Start from the year 2016, the need for more efficient hardware acceleration of AI/ML/DL was recognized in academia and industry. This year, we saw more and more players, including world’s top semiconductor companies as well as a number of startups, even tech giants Google, have jumped into the race.
> I believe that it could be very interesting to look at them together. So, I build this list of AI/ML/DL ICs and IPs on Github and keep updating. If you have any suggestion or new information, please let me know.

**[Weekly Digest Aug. 2017 \#2](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-08_2.md)**

**[Weekly Digest Aug. 2017 \#3](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-08_3.md)**

**[Weekly Digest Aug. 2017 \#4](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-08_4.md)**

**[Weekly Digest Aug. 2017 \#5](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-08_5.md)**

**[Weekly Digest Sept. 2017 \#1](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-09_1.md)**

**[Weekly Digest Sept. 2017 \#2](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-09_2.md)**

**[Weekly Digest Sept. 2017 \#3](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-09_3.md)**

**[Weekly Digest Sept. 2017 \#4](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-09_4.md)**

**[Weekly Digest Oct. 2017 \#1](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-10_1.md)**

**[Weekly Digest Oct. 2017 \#2](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-10_2.md)**

**[Weekly Digest Oct. 2017 \#3](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-10_3.md)**

**[Weekly Digest Oct. 2017 \#4](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-10_4.md)**

**[Weekly Digest Oct. 2017 \#5](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-10_5.md)**

**[Weekly Digest Nov. 2017 \#1](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-11_1.md)**
