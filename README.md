# Interesting stuff of AI/ML/DL

## Weekly Digest 2017-12 \#4

**[The Most 2017 Story of 2017](https://www.theatlantic.com/business/archive/2017/12/grinch-bots-christmas-toys/548354/)**
> It’s a Christmas tale for our time: Cyber nerds using high-tech software to buy a slew of baby-monkey robots and holding them ransom for thousands of dollars.

**[This year the world woke up to the society-shifting power of artificial intelligence](https://qz.com/1156957/this-year-the-world-woke-up-to-the-society-shifting-power-of-artificial-intelligence/)**
> And, naturally, 2018 will bring more AI research. Autonomous cars will get more precise, facial recognition will get spookier, but the question the technology raises will remain the same.

**[Thoughts on David Donoho’s "Fifty Years of Data Science"](https://simplystatistics.org/2017/12/20/thoughts-on-david-donoho-s-fifty-years-of-data-science/)**
> This post was originally published as part of a collection of discussion pieces on David Donoho’s paper. The [original paper](http://www.tandfonline.com/doi/full/10.1080/10618600.2017.1384734) and collection of discussions can be found at the [JCGS web site](http://www.tandfonline.com/toc/ucgs20/26/4).

**[Two Myths About Automation](https://www.project-syndicate.org/commentary/two-myths-about-automation-by-barry-eichengreen-2017-12)**
> While many people believe that technological progress and job destruction are accelerating dramatically, there is no evidence of either trend. In reality, total factor productivity, the best summary measure of the pace of technical change, has been stagnating since 2005 in the US and across the advanced-country world.

**[Google Has a New Plan for China (and It's Not About Search)](https://www.bloomberg.com/news/articles/2017-10-30/google-plots-grassroots-path-into-china-through-ai-investments)**
> More than seven years after exiting China, Google is taking the boldest steps yet to come back. And it’s not with a search engine.

**[Building A.I. That Can Build A.I.](https://www.nytimes.com/2017/11/05/technology/machine-learning-artificial-intelligence-ai.html)**
> Google and others, fighting for a small pool of researchers, are looking for automated ways to deal with a shortage of artificial intelligence experts.

**[188 examples of artificial intelligence in action](https://poo.ai/)**
> Because animating the poo emoji is only the beginning.

**[How many images do you need to train a neural network?](https://petewarden.com/2017/12/14/how-many-images-do-you-need-to-train-a-neural-network/)**
> Today I got an email with a question I’ve heard many times – “How many images do I need to train my classifier?“. In the early days I would reply with the technically most correct, but also useless answer of “it depends”, but over the last couple of years I’ve realized that just having a very approximate rule of thumb is useful, so here it is for posterity:
> You need 1,000 representative images for each class.

**[Superhuman AI for heads-up no-limit poker: Libratus beats top professionals](http://science.sciencemag.org/content/early/2017/12/15/science.aao1733)**
> Abstract: No-limit Texas hold’em is the most popular form of poker. Despite AI successes in perfect-information games, the private information and massive game tree have made no-limit poker difficult to tackle. We present Libratus, an AI that, in a 120,000-hand competition, defeated four top human specialist professionals in heads-up no-limit Texas hold’em, the leading benchmark and long-standing challenge problem in imperfect-information game solving. Our game-theoretic approach features application-independent techniques: an algorithm for computing a blueprint for the overall strategy, an algorithm that fleshes out the details of the strategy for subgames that are reached during play, and a self-improver algorithm that fixes potential weaknesses that opponents have identified in the blueprint strategy.

**[Applied Machine Learning at Facebook: A Datacenter Infrastructure Perspective](https://research.fb.com/publications/applied-machine-learning-at-facebook-a-datacenter-infrastructure-perspective/)**
> Abstract: Machine learning sits at the core of many essential products and services at Facebook. This paper describes the hardware and software infrastructure that supports machine learning at global scale. Facebook’s machine learning workloads are extremely diverse: services require many different types of models in practice. This diversity has implications at all layers in the system stack. In addition, a sizable fraction of all data stored at Facebook flows through machine learning pipelines, presenting significant challenges in delivering data to high-performance distributed training flows. Computational requirements are also intense, leveraging both GPU and CPU platforms for training and abundant CPU capacity for real-time inference. Addressing these and other emerging challenges continues to require diverse efforts that span machine learning algorithms, software, and hardware design. 

**[Weekly Digest Aug. 2017 \#2](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-08_2.md)**

**[Weekly Digest Aug. 2017 \#3](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-08_3.md)**

**[Weekly Digest Aug. 2017 \#4](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-08_4.md)**

**[Weekly Digest Aug. 2017 \#5](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-08_5.md)**

**[Weekly Digest Sept. 2017 \#1](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-09_1.md)**

**[Weekly Digest Sept. 2017 \#2](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-09_2.md)**

**[Weekly Digest Sept. 2017 \#3](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-09_3.md)**

**[Weekly Digest Sept. 2017 \#4](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-09_4.md)**

**[Weekly Digest Oct. 2017 \#1](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-10_1.md)**

**[Weekly Digest Oct. 2017 \#2](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-10_2.md)**

**[Weekly Digest Oct. 2017 \#3](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-10_3.md)**

**[Weekly Digest Oct. 2017 \#4](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-10_4.md)**

**[Weekly Digest Oct. 2017 \#5](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-10_5.md)**

**[Weekly Digest Nov. 2017 \#1](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-11_1.md)**

**[Weekly Digest Nov. 2017 \#2](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-11_2.md)**

**[Weekly Digest Nov. 2017 \#3](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-11_3.md)**

**[Weekly Digest Nov. 2017 \#4](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-11_4.md)**

**[Weekly Digest Dec. 2017 \#1](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-12_1.md)**

**[Weekly Digest Dec. 2017 \#2](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-12_2.md)**

**[Weekly Digest Dec. 2017 \#3](https://github.com/basicmi/Machine-Learning-Articles/blob/master/WeeklyDigest2017-12_3.md)**
