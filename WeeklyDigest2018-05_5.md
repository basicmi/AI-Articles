## AI Articles of the week

**[Europe, not the U.S., is now the most powerful regulator of Silicon Valley](https://www.washingtonpost.com/amphtml/business/technology/europe-not-the-us-is-now-the-most-powerful-regulator-of-silicon-valley/2018/05/25/f7dfb600-604f-11e8-8c93-8cf33c21da8d_story.html?noredirect=on&utm_term=.27c8371188b8&__twitter_impression=true)**
> Europe implemented a sweeping overhaul of digital-privacy laws on Friday that has reshaped how technology companies handle customer data, creating a de-facto global standard that gives Americans new protections and the nation’s technology companies new headaches.

**[Navigating the risks of artificial intelligence and machine learning in low-income countries](https://techcrunch.com/2018/05/24/navigating-the-risks-of-artificial-intelligence-and-machine-learning-in-low-income-countries/)**
> Based on ongoing research and interviews with aid workers and technology firms, we’ve learned five basic things to keep in mind when applying AI and ML in low-income countries

**[Facebook Is Designing Its Own Chips to Help Filter Live Videos](https://www.bloomberg.com/news/articles/2018-05-25/facebook-is-designing-its-own-chips-to-help-filter-live-videos)**
> Facebook Inc. is working on designing computer-chips that are more energy-efficient at analyzing and filtering live video content, its chief artificial intelligence scientist Yann LeCun said.

**[Why AI Will Bring an Explosion of New Jobs](https://hackernoon.com/why-ai-will-bring-an-explosion-of-new-jobs-11dc203890b)**
> What if it’s not the end of work but the beginning of a massive job boom unlike anything we’ve ever seen in history?

**[Skill shift: Automation and the future of the workforce](https://www.mckinsey.com/featured-insights/future-of-organizations-and-work/skill-shift-automation-and-the-future-of-the-workforce)**
> Demand for technological, social and emotional, and higher cognitive skills will rise by 2030. How will workers and organizations adapt?

**[LOTS OF LOBBIES AND ZERO ZOMBIES: HOW SELF-DRIVING CARS WILL RESHAPE CITIES](https://www.wired.com/story/self-driving-cars-cities/)**
> some ideas for how urban planners of the future might reimagine those outdated layouts—and transform the city into a joyful mess of throughways and byways optimized not for cars but for people.

**[Does the brain store information in discrete or analog form?](https://www.technologyreview.com/s/611165/does-the-brain-store-information-in-discrete-or-analog-form/)**
> New evidence in favor of a discrete form of data storage could change the way we understand the brain and the devices we build to interface with it.

**[Basic instincts](http://science.sciencemag.org/content/360/6391/845.full)**
> Some say artificial intelligence needs to learn like a child.

**[Growing up with AI: How can families play and learn with their new smart toys and companions?](https://medium.com/mit-media-lab/growing-up-with-ai-how-can-families-play-and-learn-with-their-new-smart-toys-and-companions-fe9abcc6e152)**
> what this experience will look like for today’s children, who are not just growing up with the web, but are also the first generation of kids to grow up with artificial intelligence (AI) in their daily lives.

**[Deep Convolutional Neural Networks as Models of the Visual System: Q&A](https://neurdiness.wordpress.com/2018/05/17/deep-convolutional-neural-networks-as-models-of-the-visual-system-qa/)**
> Q&A format to paint a fairly reasonable and accurate picture of the use of CNNs for modeling biological vision.

**[Standardizing a Machine Learning Framework for Applied Research – PyTorch vs MXNet](http://www.borealisai.com/2018/02/16/standardizing-a-machine-learning-framework-for-applied-research/)**
> Until now, the Machine Learning (ML) frameworks we’ve used at Borealis AI have varied according to individual preference. But as our applied team grows, we’re finding that a preference-based system has certain shortcomings that have led to inefficiencies and delays in our research projects. As a result, we identified two main arguments in favour of standardizing a single framework for the lab.

**[Categorizing Listing Photos at Airbnb](https://medium.com/airbnb-engineering/categorizing-listing-photos-at-airbnb-f9483f3ab7e3)**
> Large-scale deep learning models are changing the way we think about images of homes on our platform.

**[“That’s Mental!” Using LDA Topic Modeling to Investigate the Discourse on Mental Health over Time](https://towardsdatascience.com/thats-mental-using-lda-topic-modeling-to-investigate-the-discourse-on-mental-health-over-time-11da252259c3)**
> For this project I set out to investigate the contexts in which ‘mental health’ has been brought up over time. For this purpose, I collected ~30k New York Times articles from the 80s to present to analyze using topic modeling.

**[Russian Natural Language Processing](https://blog.primer.ai/technology/2018/05/22/Russian-Natural-Language-Processing.html)**
> Is there really one NLP language model to rule them all?

**[Into a Textual Heart of Darkness](https://towardsdatascience.com/into-a-textual-heart-of-darkness-39b3895ce21e)**
> Going zero to not-quite-hero in NLP via hate speech classification

**[Self-Attention Generative Adversarial Networks](https://arxiv.org/abs/1805.08318)**
> In this paper, we propose the Self-Attention Generative Adversarial Network (SAGAN) which allows attention-driven, long-range dependency modeling for image generation tasks. Traditional convolutional GANs generate high-resolution details as a function of only spatially local points in lower-resolution feature maps. In SAGAN, details can be generated using cues from all feature locations. Moreover, the discriminator can check that highly detailed features in distant portions of the image are consistent with each other. Furthermore, recent work has shown that generator conditioning affects GAN performance. Leveraging this insight, we apply spectral normalization to the GAN generator and find that this improves training dynamics. The proposed SAGAN achieves the state-of-the-art results, boosting the best published Inception score from 36.8 to 52.52 and reducing Frechet Inception distance from 27.62 to 18.65 on the challenging ImageNet dataset. Visualization of the attention layers shows that the generator leverages neighborhoods that correspond to object shapes rather than local regions of fixed shape.


