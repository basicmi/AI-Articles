## Weekly Digest 2018-02 \#2

**[Just How Shallow is the Artificial Intelligence Talent Pool?](https://www.bloomberg.com/news/articles/2018-02-07/just-how-shallow-is-the-artificial-intelligence-talent-pool)**
> Research from Element AI indicates only 22,000 have right skills globally

**[Why Deep Learning Needs Standards for Industrialization](https://medium.com/intuitionmachine/challenges-for-ai-standardization-eab1de4fab0b)**
> "I was recently was posed the question, “how do we define standards for AI?” I am primarily focused in the space of Deep Learning Artificial Intelligence (AI)."

**[New quantum linear system algorithm could speed up machine learning](https://www.opengovasia.com/articles/new-quantum-linear-system-algorithm-could-speed-up-machine-learning)**
> The researchers have proposed a new algorithm for solving systems of linear equations that is faster than both the classical and the previous quantum versions, and without restrictions on the kind of data it works for.

**[Facial Recognition Is Accurate, if You’re a White Guy](https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-artificial-intelligence.html)**
> When the person in the photo is a white man, the software is right 99 percent of the time.
> But the darker the skin, the more errors arise — up to nearly 35 percent for images of darker skinned women, according to a new study that breaks fresh ground by measuring how the technology works on people of different races and gender.

**[Philosophers are building ethical algorithms to help control self-driving cars](https://qz.com/1204395/self-driving-cars-trolley-problem-philosophers-are-building-ethical-algorithms-to-solve-the-problem/)**
> Artificial intelligence experts and roboticists aren’t the only ones working on the problem of autonomous vehicles. Philosophers are also paying close attention to the development of what, from their perspective, looks like a myriad of ethical quandaries on wheels.

**[Making Sense of the Bias / Variance Trade-off in (Deep) Reinforcement Learning](https://medium.com/mlreview/making-sense-of-the-bias-variance-trade-off-in-deep-reinforcement-learning-79cf1e83d565)**
> What goes into a stable, accurate reinforcement signal?

**[A Code of Ethics for Data Science](https://medium.com/@dpatil/a-code-of-ethics-for-data-science-cda27d1fac1)**
> 2.5 quintillion bytes of data are created every day. It’s created by you when you’re commute to work or school, when you’re shopping, when you get a medical treatment, and even when you’re sleeping. It’s created by you, your neighbors, and everyone around you. So, how do we ensure it’s used ethically?

**[Experts say AI isn't quite fire or the wheel — yet]()**
> [Some researchers](https://medium.com/@Synced/artificial-intelligence-is-the-new-electricity-andrew-ng-cc132ea6264) and [business leaders](http://money.cnn.com/2018/01/24/technology/sundar-pichai-google-ai-artificial-intelligence/index.html) are putting artificial intelligence — in its current and aspirational forms — on the same pedestal of human invention and innovation as fire, electricity and the light bulb. But other experts say we will not know for a long time whether AI will ever merit such lofty imagery.

**[Can Computers Learn Like Humans?](https://www.npr.org/sections/alltechconsidered/2018/02/05/583321707/can-computers-learn-like-humans)**

